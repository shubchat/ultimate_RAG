{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6d5fe9-de64-46b8-a5fb-0a02021ec710",
   "metadata": {},
   "source": [
    "# Building a RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5214e-a3f8-4b39-bf32-0b4137650340",
   "metadata": {},
   "source": [
    "## A Basic RAG Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3a45eb4-b4c7-451b-bce4-befdaf001a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "graph TD\n",
       "    A[User Input] -->|Query| B(Retriever)\n",
       "    B <-->|Fetch/Return Documents| C[(Knowledge Base / Document Store)]\n",
       "    B -->|Retrieved Context| D(Language Model LLM)\n",
       "    A -->|Original Query| D\n",
       "    D --> E[Generated Response]\n",
       "\n",
       "    classDef input fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:black;\n",
       "    classDef process fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:black;\n",
       "    classDef data fill:#fff3e0,stroke:#ff6f00,stroke-width:2px,color:black;\n",
       "    classDef output fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:black;\n",
       "\n",
       "    class A input;\n",
       "    class B,D process;\n",
       "    class C data;\n",
       "    class E output;\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "# Load the mermaid file\n",
    "mermaid_file = \"rag-system-architecture.mermaid\"\n",
    "with open(mermaid_file, \"r\") as file:\n",
    "    mermaid_code = file.read()\n",
    "\n",
    "# Display the Mermaid diagram\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_code}\\n```\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66864724-5e24-46c0-90fd-06d4351e13ed",
   "metadata": {},
   "source": [
    "### Let's take a quick peek into the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "755708d2-05e7-4a0e-952c-c2243d64fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive.zip                      rag-system-architecture.mermaid\n",
      "arxiv-metadata-oai-snapshot.json tfidf_index_arxiv.pkl\n",
      "building_basic_RAG_system.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97f0fec2-7fca-4c84-a353-03dfa98d3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Method 1: Quick peek at first few records\n",
    "def peek_multiple_records(num_records=3):\n",
    "    with open('arxiv-metadata-oai-snapshot.json', 'r') as f:\n",
    "        for i in range(num_records):\n",
    "            try:\n",
    "                data = json.loads(next(f))\n",
    "                print(f\"\\nRecord {i+1}:\")\n",
    "                print(json.dumps(data, indent=2))\n",
    "            except StopIteration:\n",
    "                print(\"Reached end of file\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aec4bf11-cf6b-40b5-b467-3c01e13e9cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Record 1:\n",
      "{\n",
      "  \"id\": \"0704.0001\",\n",
      "  \"submitter\": \"Pavel Nadolsky\",\n",
      "  \"authors\": \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
      "  \"title\": \"Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies\",\n",
      "  \"comments\": \"37 pages, 15 figures; published version\",\n",
      "  \"journal-ref\": \"Phys.Rev.D76:013009,2007\",\n",
      "  \"doi\": \"10.1103/PhysRevD.76.013009\",\n",
      "  \"report-no\": \"ANL-HEP-PR-07-12\",\n",
      "  \"categories\": \"hep-ph\",\n",
      "  \"license\": null,\n",
      "  \"abstract\": \"  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n\",\n",
      "  \"versions\": [\n",
      "    {\n",
      "      \"version\": \"v1\",\n",
      "      \"created\": \"Mon, 2 Apr 2007 19:18:42 GMT\"\n",
      "    },\n",
      "    {\n",
      "      \"version\": \"v2\",\n",
      "      \"created\": \"Tue, 24 Jul 2007 20:10:27 GMT\"\n",
      "    }\n",
      "  ],\n",
      "  \"update_date\": \"2008-11-26\",\n",
      "  \"authors_parsed\": [\n",
      "    [\n",
      "      \"Bal\\u00e1zs\",\n",
      "      \"C.\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Berger\",\n",
      "      \"E. L.\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Nadolsky\",\n",
      "      \"P. M.\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Yuan\",\n",
      "      \"C. -P.\",\n",
      "      \"\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\n",
      "Record 2:\n",
      "{\n",
      "  \"id\": \"0704.0002\",\n",
      "  \"submitter\": \"Louis Theran\",\n",
      "  \"authors\": \"Ileana Streinu and Louis Theran\",\n",
      "  \"title\": \"Sparsity-certifying Graph Decompositions\",\n",
      "  \"comments\": \"To appear in Graphs and Combinatorics\",\n",
      "  \"journal-ref\": null,\n",
      "  \"doi\": null,\n",
      "  \"report-no\": null,\n",
      "  \"categories\": \"math.CO cs.CG\",\n",
      "  \"license\": \"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\",\n",
      "  \"abstract\": \"  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n\",\n",
      "  \"versions\": [\n",
      "    {\n",
      "      \"version\": \"v1\",\n",
      "      \"created\": \"Sat, 31 Mar 2007 02:26:18 GMT\"\n",
      "    },\n",
      "    {\n",
      "      \"version\": \"v2\",\n",
      "      \"created\": \"Sat, 13 Dec 2008 17:26:00 GMT\"\n",
      "    }\n",
      "  ],\n",
      "  \"update_date\": \"2008-12-13\",\n",
      "  \"authors_parsed\": [\n",
      "    [\n",
      "      \"Streinu\",\n",
      "      \"Ileana\",\n",
      "      \"\"\n",
      "    ],\n",
      "    [\n",
      "      \"Theran\",\n",
      "      \"Louis\",\n",
      "      \"\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\n",
      "Record 3:\n",
      "{\n",
      "  \"id\": \"0704.0003\",\n",
      "  \"submitter\": \"Hongjun Pan\",\n",
      "  \"authors\": \"Hongjun Pan\",\n",
      "  \"title\": \"The evolution of the Earth-Moon system based on the dark matter field\\n  fluid model\",\n",
      "  \"comments\": \"23 pages, 3 figures\",\n",
      "  \"journal-ref\": null,\n",
      "  \"doi\": null,\n",
      "  \"report-no\": null,\n",
      "  \"categories\": \"physics.gen-ph\",\n",
      "  \"license\": null,\n",
      "  \"abstract\": \"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior of the Earth-Moon system agrees\\nwith this model very well and the general pattern of the evolution of the\\nMoon-Earth system described by this model agrees with geological and fossil\\nevidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\\nbillion years ago, which is far beyond the Roche's limit. The result suggests\\nthat the tidal friction may not be the primary cause for the evolution of the\\nEarth-Moon system. The average dark matter field fluid constant derived from\\nEarth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\\nthat the Mars's rotation is also slowing with the angular acceleration rate\\nabout -4.38 x 10^(-22) rad s^(-2).\\n\",\n",
      "  \"versions\": [\n",
      "    {\n",
      "      \"version\": \"v1\",\n",
      "      \"created\": \"Sun, 1 Apr 2007 20:46:54 GMT\"\n",
      "    },\n",
      "    {\n",
      "      \"version\": \"v2\",\n",
      "      \"created\": \"Sat, 8 Dec 2007 23:47:24 GMT\"\n",
      "    },\n",
      "    {\n",
      "      \"version\": \"v3\",\n",
      "      \"created\": \"Sun, 13 Jan 2008 00:36:28 GMT\"\n",
      "    }\n",
      "  ],\n",
      "  \"update_date\": \"2008-01-13\",\n",
      "  \"authors_parsed\": [\n",
      "    [\n",
      "      \"Pan\",\n",
      "      \"Hongjun\",\n",
      "      \"\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "peek_multiple_records(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d111be9-7257-42fe-8d7b-0163da85043b",
   "metadata": {},
   "source": [
    "## Basic Retrieval without LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c830d0-e7b9-4253-9774-2895a60c4709",
   "metadata": {},
   "source": [
    "### Step1: Create an index and get [TFIDF](https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/) for each article/abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc0f4d72-3aa0-408e-9ff8-8901a8d9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def create_index(json_path, index_save_path='tfidf_index_arxiv.pkl'):\n",
    "    # Initialize lists to store data\n",
    "    documents = []\n",
    "    metadata = []  # Store title, id, etc separately to save memory\n",
    "    \n",
    "    # Read and process documents in chunks\n",
    "    print(\"Reading documents...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            article = json.loads(line)\n",
    "            # Store minimal text for TFIDF\n",
    "            documents.append(f\"{article['title']} {article['abstract']}\")\n",
    "            # Store metadata separately\n",
    "            metadata.append({\n",
    "                'title': article['title'],\n",
    "                'abstract': article['abstract']\n",
    "            })\n",
    "    \n",
    "    print(\"Creating TFIDF vectors...\")\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    print(\"Saving index...\")\n",
    "    with open(index_save_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'vectorizer': vectorizer,\n",
    "            'tfidf_matrix': tfidf_matrix,\n",
    "            'metadata': metadata\n",
    "        }, f)\n",
    "    \n",
    "    print(\"Index created and saved!\")\n",
    "    return vectorizer, tfidf_matrix, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f58dbfc1-1486-41c7-8c97-1bbdb0c52fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2631725it [00:31, 84045.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TFIDF vectors...\n",
      "Saving index...\n",
      "Index created and saved!\n"
     ]
    }
   ],
   "source": [
    "vectorizer, tfidf_matrix, metadata = create_index('arxiv-metadata-oai-snapshot.json', index_save_path='tfidf_index_arxiv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f157c0-b265-4867-b9a0-fd3768773f09",
   "metadata": {},
   "source": [
    "### Step2:Now time to creat an interface for Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bb8f9b2-6748-4f79-89d0-75fdefa108e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class Searcher:\n",
    "    def __init__(self, index_path='tfidf_index_arxiv.pkl'):\n",
    "        print(\"Loading index...\")\n",
    "        with open(index_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.vectorizer = data['vectorizer']\n",
    "            self.tfidf_matrix = data['tfidf_matrix']\n",
    "            self.metadata = data['metadata']\n",
    "    \n",
    "    def search(self, query, top_k=5):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'title': self.metadata[idx]['title'],\n",
    "                'abstract': self.metadata[idx]['abstract'],\n",
    "                'score': similarities[idx]\n",
    "            })\n",
    "        return results\n",
    "\n",
    "# Gradio interface\n",
    "def setup_gradio():\n",
    "    searcher = Searcher()\n",
    "    \n",
    "    def search_documents(query):\n",
    "        results = searcher.search(query)\n",
    "        output = \"\"\n",
    "        for i, res in enumerate(results, 1):\n",
    "            output += f\"Result {i} (Score: {res['score']:.3f})\\n\"\n",
    "            output += f\"Title: {res['title']}\\n\"\n",
    "            output += f\"Abstract: {res['abstract']}\\n\\n\"\n",
    "        return output\n",
    "\n",
    "    iface = gr.Interface(\n",
    "        fn=search_documents,\n",
    "        inputs=gr.Textbox(lines=2, placeholder=\"Enter your search query...\"),\n",
    "        outputs=gr.Textbox(lines=20),\n",
    "        title=\"ArXiv Paper Search using TF-IDF\",\n",
    "        description=\"Search through ArXiv papers using TF-IDF based similarity\"\n",
    "    )\n",
    "    return iface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "300e139f-b23e-47d7-9a77-00d1cba28488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index...\n",
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = setup_gradio()\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf172ce-326c-4361-b615-e134dd3cfc1d",
   "metadata": {},
   "source": [
    "# API Keys and Secrets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d19171d6-1884-443f-a1a8-6cd1375705d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Azure openAI credentials\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = \"\", \n",
    "    api_key=\"\",  \n",
    "    api_version=\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7df83-3c8e-423e-85c7-33dda3274d65",
   "metadata": {},
   "source": [
    "# Arxiv paper chatbot using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e6e2ecf-2421-4578-8043-2f75fc3b9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "294649d8-1c06-498a-8b46-c3b2923ec88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "import gradio as gr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "class ArxivBot:\n",
    "    def __init__(self, index_path='tfidf_index_arxiv.pkl', deployment_name=deployment_name,client=client):\n",
    "        # Initialize Azure OpenAI client\n",
    "        self.client = client\n",
    "        self.deployment_name = deployment_name\n",
    "\n",
    "        # Load TFIDF index\n",
    "        print(\"Loading index...\")\n",
    "        with open(index_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.vectorizer = data['vectorizer']\n",
    "            self.tfidf_matrix = data['tfidf_matrix']\n",
    "            self.metadata = data['metadata']\n",
    "\n",
    "    def search(self, query, top_k=3):\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'title': self.metadata[idx]['title'],\n",
    "                'abstract': self.metadata[idx]['abstract'],\n",
    "                'score': similarities[idx]\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def get_response(self, query, history):\n",
    "        # Search relevant papers\n",
    "        search_results = self.search(query)\n",
    "        \n",
    "        # Prepare context from search results\n",
    "        \n",
    "        for i, res in enumerate(search_results, 1):\n",
    "            retrieved_papers = \"\\n\".join([\n",
    "                                            f\"[Paper {i}]\\n\"\n",
    "                                            f\"Title: {res['title']}\\n\"\n",
    "                                            f\"Abstract: {res['abstract']}\\n\"\n",
    "                                            f\"Relevance Score: {res['score']:.2f}\\n\"\n",
    "                                            for i, res in enumerate(search_results, 1)\n",
    "                                        ])\n",
    "\n",
    "        # Prepare messages for GPT-4\n",
    "        messages = [\n",
    "            { \"role\": \"system\",\n",
    "        \"content\": f\"\"\"You are ArxivBot, a specialized research assistant focusing on arXiv papers. You are currently analyzing these relevant papers:\n",
    "\n",
    "                                {retrieved_papers}\n",
    "                                \n",
    "                                Your goal is to provide informative and helpful responses:\n",
    "            1. Use the information from the papers to provide detailed, substantive answers\n",
    "            2. When papers contain relevant information, explain the concepts thoroughly\n",
    "            3. If papers partially address the question, share what information is available and explain how it relates\n",
    "            4. Only mention limitations if the papers truly contain no relevant information\n",
    "            \n",
    "            When responding:\n",
    "            - Synthesize information across multiple papers when relevant\n",
    "            - Explain technical concepts in an accessible way\n",
    "            - Cite papers using \"Paper X mentions/discusses/shows...\"\n",
    "            - Focus on being helpful while maintaining accuracy\n",
    "                                \"\"\"},\n",
    "        ]\n",
    "        \n",
    "        # Add chat history\n",
    "        for h in history:\n",
    "            messages.append({\"role\": \"user\", \"content\": h[0]})\n",
    "            if h[1]:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": h[1]})\n",
    "        \n",
    "        # Add current query\n",
    "        messages.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "        # Get response from GPT-4\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment_name,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def chat_with_arxiv():\n",
    "    bot = ArxivBot()\n",
    "    \n",
    "    with gr.Blocks() as demo:\n",
    "        chatbot = gr.Chatbot(label=\"Chat with ArxivBot\")\n",
    "        msg = gr.Textbox(label=\"Message\")\n",
    "        clear = gr.Button(\"Clear\")\n",
    "        \n",
    "        def user(user_message, history):\n",
    "            return \"\", history + [[user_message, None]]\n",
    "        \n",
    "        def bot_response(history):\n",
    "            response = bot.get_response(history[-1][0], history[:-1])\n",
    "            history[-1][1] = response\n",
    "            return history\n",
    "        \n",
    "        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "            bot_response, chatbot, chatbot\n",
    "        )\n",
    "        clear.click(lambda: None, None, chatbot, queue=False)\n",
    "    \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7691424e-258d-4213-b7ed-d329236660f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yougandharadeshmukh/Shubh/youtube/10.Ultimate_RAG_tutorial/code_artifacts/.env/lib/python3.11/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = chat_with_arxiv()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08b2c9-ce20-42e0-9390-cf27b6afcd39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
